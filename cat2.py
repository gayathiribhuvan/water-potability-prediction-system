import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import QuantileTransformer
from sklearn.experimental import enable_iterative_imputer
from sklearn.impute import IterativeImputer
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score, f1_score
from sklearn.ensemble import ExtraTreesClassifier
from sklearn.feature_selection import SelectFromModel
from lightgbm import LGBMClassifier
from catboost import CatBoostClassifier
from sklearn.neural_network import MLPClassifier
from imblearn.combine import SMOTEENN
import pickle
import warnings
warnings.filterwarnings('ignore')

st.set_page_config(
    page_title="Water Potability Predictor",
    page_icon="üíß",
    layout="wide",
    initial_sidebar_state="expanded"
)

st.markdown("""
    <style>
    .main {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
    }
    .stApp {
        background: linear-gradient(135deg, #f5f7fa 0%, #c3cfe2 100%);
    }
    h1 {
        color: #1e3a8a;
        font-family: 'Helvetica Neue', sans-serif;
        text-align: center;
        padding: 20px;
        background: linear-gradient(90deg, #667eea 0%, #764ba2 100%);
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
        font-weight: 800;
    }
    h2 {
        color: #3730a3;
        font-weight: 700;
    }
    h3 {
        color: #4338ca;
        font-weight: 600;
    }
    .stButton>button {
        background: linear-gradient(90deg, #667eea 0%, #764ba2 100%);
        color: white;
        font-weight: bold;
        border-radius: 10px;
        padding: 10px 24px;
        border: none;
        box-shadow: 0 4px 6px rgba(0,0,0,0.1);
        transition: all 0.3s ease;
    }
    .stButton>button:hover {
        transform: translateY(-2px);
        box-shadow: 0 6px 12px rgba(0,0,0,0.15);
    }
    .metric-card {
        background: white;
        padding: 20px;
        border-radius: 10px;
        box-shadow: 0 4px 6px rgba(0,0,0,0.1);
        margin: 10px 0;
    }
    .sidebar .sidebar-content {
        background: linear-gradient(180deg, #667eea 0%, #764ba2 100%);
    }
    </style>
""", unsafe_allow_html=True)

if 'trained' not in st.session_state:
    st.session_state.trained = False
if 'models' not in st.session_state:
    st.session_state.models = {}
if 'scaler' not in st.session_state:
    st.session_state.scaler = None
if 'selected_features' not in st.session_state:
    st.session_state.selected_features = []
if 'best_threshold' not in st.session_state:
    st.session_state.best_threshold = 0.5
if 'df' not in st.session_state:
    st.session_state.df = None

st.markdown("<h1>üíß Water Potability Prediction System</h1>", unsafe_allow_html=True)

with st.sidebar:
    st.markdown("###  Navigation")
    page = st.radio("Go to", ["Home", "EDA", "Train Model", "Predict", "Model Performance"])
    
    st.markdown("---")
    st.markdown("### üìÅ Upload Dataset")
    uploaded_file = st.file_uploader("Upload CSV file", type=['csv'])
    
    if uploaded_file is not None:
        st.session_state.df = pd.read_csv(uploaded_file)
        st.success(f"‚úÖ Loaded {len(st.session_state.df)} samples")
    
    st.markdown("---")
    st.markdown("### ‚ÑπÔ∏è About")
    st.info("This application predicts water potability using machine learning. Upload your dataset, explore it, train models, and make predictions!")

if page == "Home":
    col1, col2, col3 = st.columns([1, 2, 1])
    
    with col2:
        st.markdown("<h3 style='color: #1f2937;'>Welcome to Water Potability Predictor! üëã</h3>", unsafe_allow_html=True)
        st.markdown("""
        <div style='color: #1f2937;'>
        <p>This application helps you determine whether water samples are safe for consumption using advanced machine learning algorithms.</p>
        
        <h4 style='color: #1f2937;'>üöÄ Features:</h4>
        <ul>
        <li><strong>Interactive EDA:</strong> Visualize and explore your water quality dataset</li>
        <li><strong>Advanced ML Models:</strong> LightGBM, CatBoost, Extra Trees & Neural Networks</li>
        <li><strong>Ensemble Learning:</strong> Combines multiple models for superior accuracy</li>
        <li><strong>Real-time Predictions:</strong> Get instant potability predictions</li>
        <li><strong>Performance Metrics:</strong> Detailed model evaluation and insights</li>
        </ul>
        
        <h4 style='color: #1f2937;'>üìã How to Use:</h4>
        <ol>
        <li><strong>Upload Dataset:</strong> Use the sidebar to upload your water quality CSV file</li>
        <li><strong>Explore Data:</strong> Navigate to EDA section for visual analysis</li>
        <li><strong>Train Models:</strong> Train the AI models on your dataset</li>
        <li><strong>Make Predictions:</strong> Input water parameters to check potability</li>
        <li><strong>Review Performance:</strong> Check model accuracy and metrics</li>
        </ol>
        
        <h4 style='color: #1f2937;'>üß™ Required Features:</h4>
        <p>Your dataset should contain these water quality parameters:</p>
        <ul>
        <li>pH, Hardness, Solids, Chloramines, Sulfate</li>
        <li>Conductivity, Organic Carbon, Trihalomethanes, Turbidity</li>
        <li>Potability (0 = Not Potable, 1 = Potable)</li>
        </ul>
        </div>
        """, unsafe_allow_html=True)
        
        if st.session_state.df is not None:
            st.success("‚úÖ Dataset loaded! Navigate to other sections to continue.")
        else:
            st.warning("‚ö†Ô∏è Please upload a dataset to get started.")


elif page == "EDA":
    st.markdown("## Exploratory Data Analysis")
    
    if st.session_state.df is None:
        st.warning("‚ö†Ô∏è Please upload a dataset first!")
    else:
        df = st.session_state.df
        
        st.markdown("### üìã Dataset Overview")
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric("Total Samples", len(df))
        with col2:
            st.metric("Features", len(df.columns) - 1)
        with col3:
            st.metric("Potable Samples", int(df['Potability'].sum()))
        with col4:
            st.metric("Non-Potable Samples", int(len(df) - df['Potability'].sum()))
        
        st.markdown("---")
        
        with st.expander("üîç View Raw Data"):
            st.dataframe(df.head(100), use_container_width=True)
        
        with st.expander("üìà Statistical Summary"):
            st.dataframe(df.describe(), use_container_width=True)
        
        st.markdown("---")
        
        st.markdown("### üìâ Data Visualizations")
        
        tab1, tab2, tab3, tab4, tab5 = st.tabs(["Class Distribution", "Missing Values", "Feature Distributions", "Correlations", "Outliers"])
        
        with tab1:
            st.markdown("#### Water Potability Class Distribution")
            fig, ax = plt.subplots(figsize=(10, 6))
            colors = ['#FF6B6B', '#4ECDC4']
            counts = df['Potability'].value_counts()
            bars = ax.bar(['Not Potable (0)', 'Potable (1)'], counts.values, color=colors, edgecolor='black', linewidth=2)
            ax.set_ylabel('Count', fontsize=12, fontweight='bold')
            ax.set_xlabel('Potability Status', fontsize=12, fontweight='bold')
            ax.set_title('Class Distribution of Water Potability', fontsize=14, fontweight='bold', pad=15)
            
            for i, bar in enumerate(bars):
                height = bar.get_height()
                ax.text(bar.get_x() + bar.get_width()/2., height,
                       f'{int(height)}\n({height/len(df)*100:.1f}%)',
                       ha='center', va='bottom', fontsize=12, fontweight='bold')
            
            st.pyplot(fig)
            
            col1, col2 = st.columns(2)
            with col1:
                st.info(f"**Imbalance Ratio:** {counts[0] / counts[1]:.2f}:1")
            with col2:
                st.info(f"**Total Samples:** {len(df)}")
        
        with tab2:
            st.markdown("#### Missing Values Analysis")
            missing_data = df.isnull().sum().sort_values(ascending=False)
            missing_data = missing_data[missing_data > 0]
            
            if len(missing_data) > 0:
                fig, ax = plt.subplots(figsize=(10, 6))
                colors_missing = ['#E63946' if x > 500 else '#F77F00' if x > 200 else '#FCBF49' 
                                for x in missing_data.values]
                bars = ax.barh(missing_data.index, missing_data.values, color=colors_missing, edgecolor='black', linewidth=1.5)
                ax.set_xlabel('Number of Missing Values', fontsize=12, fontweight='bold')
                ax.set_title('Missing Values Analysis', fontsize=14, fontweight='bold', pad=15)
                
                for i, (bar, value) in enumerate(zip(bars, missing_data.values)):
                    ax.text(value + 20, bar.get_y() + bar.get_height()/2, 
                           f'{int(value)} ({value/len(df)*100:.1f}%)',
                           va='center', fontsize=11, fontweight='bold')
                
                st.pyplot(fig)
            else:
                st.success("‚úÖ No missing values in the dataset!")
        
        with tab3:
            st.markdown("#### Feature Distributions by Potability")
            features = df.columns[:-1]
            
            fig, axes = plt.subplots(3, 3, figsize=(18, 14))
            axes = axes.flatten()
            
            for idx, feature in enumerate(features):
                ax = axes[idx]
                potable = df[df['Potability'] == 1][feature].dropna()
                not_potable = df[df['Potability'] == 0][feature].dropna()
                
                ax.hist(not_potable, bins=30, alpha=0.6, label='Not Potable', color='#FF6B6B', edgecolor='black')
                ax.hist(potable, bins=30, alpha=0.6, label='Potable', color='#4ECDC4', edgecolor='black')
                
                ax.set_title(f'{feature}', fontsize=12, fontweight='bold')
                ax.set_xlabel(feature, fontsize=10)
                ax.set_ylabel('Frequency', fontsize=10)
                ax.legend(loc='upper right')
                ax.grid(alpha=0.3)
            
            plt.tight_layout()
            st.pyplot(fig)
        
        with tab4:
            st.markdown("#### Feature Correlation Matrix")
            fig, ax = plt.subplots(figsize=(12, 10))
            correlation = df.corr()
            mask = np.triu(np.ones_like(correlation, dtype=bool))
            
            sns.heatmap(correlation, mask=mask, annot=True, fmt='.2f', cmap='coolwarm', 
                       center=0, square=True, linewidths=1, cbar_kws={"shrink": 0.8},
                       vmin=-1, vmax=1, ax=ax)
            ax.set_title('Feature Correlation Matrix', fontsize=14, fontweight='bold', pad=15)
            
            st.pyplot(fig)
        
        with tab5:
            st.markdown("#### Box Plots - Outlier Detection")
            features = df.columns[:-1]
            
            fig, axes = plt.subplots(3, 3, figsize=(18, 14))
            axes = axes.flatten()
            
            for idx, feature in enumerate(features):
                ax = axes[idx]
                data_to_plot = [df[df['Potability'] == 0][feature].dropna(),
                               df[df['Potability'] == 1][feature].dropna()]
                
                bp = ax.boxplot(data_to_plot, labels=['Not Potable', 'Potable'],
                               patch_artist=True, notch=True, widths=0.6)
                
                colors_box = ['#FF6B6B', '#4ECDC4']
                for patch, color in zip(bp['boxes'], colors_box):
                    patch.set_facecolor(color)
                    patch.set_alpha(0.7)
                
                ax.set_title(f'{feature}', fontsize=12, fontweight='bold')
                ax.set_ylabel('Value', fontsize=10)
                ax.grid(alpha=0.3, axis='y')
            
            plt.tight_layout()
            st.pyplot(fig)

elif page == "Train Model":
    st.markdown("## Train Machine Learning Models")
    
    if st.session_state.df is None:
        st.warning("‚ö†Ô∏è Please upload a dataset first!")
    else:
        st.markdown("""
        <div style='color: #1f2937;'>
        <h3>Training Pipeline Overview:</h3>
        <ol>
        <li><strong>Advanced Imputation</strong> - Handle missing values intelligently</li>
        <li><strong>Feature Engineering</strong> - Create 45+ advanced features</li>
        <li><strong>Feature Selection</strong> - Select most important features</li>
        <li><strong>Data Scaling</strong> - Normalize data using QuantileTransformer</li>
        <li><strong>SMOTEENN Resampling</strong> - Balance classes intelligently</li>
        <li><strong>Model Training</strong> - Train 4 state-of-the-art models</li>
        <li><strong>Ensemble Creation</strong> - Combine models with optimal weighting</li>
        </ol>
        </div>
        """, unsafe_allow_html=True)
        
        if st.button(" Start Training", use_container_width=True):
            with st.spinner("Training in progress... This may take a few minutes."):
                progress_bar = st.progress(0)
                status_text = st.empty()
                
                df = st.session_state.df
                
                status_text.text("Step 1/7: Performing advanced imputation...")
                progress_bar.progress(10)
                imputer = IterativeImputer(max_iter=20, random_state=42, tol=0.001)
                df_imputed = pd.DataFrame(imputer.fit_transform(df), columns=df.columns)
                
                status_text.text("Step 2/7: Creating advanced features...")
                progress_bar.progress(25)
                original_features = df_imputed.copy()
                
                df_imputed['ph_Hardness'] = df_imputed['ph'] * df_imputed['Hardness']
                df_imputed['ph_Sulfate'] = df_imputed['ph'] * df_imputed['Sulfate']
                df_imputed['Solids_Sulfate'] = df_imputed['Solids'] * df_imputed['Sulfate']
                df_imputed['Solids_Conductivity'] = df_imputed['Solids'] * df_imputed['Conductivity']
                df_imputed['Organic_Chloramines'] = df_imputed['Organic_carbon'] * df_imputed['Chloramines']
                df_imputed['Conductivity_Sulfate'] = df_imputed['Conductivity'] * df_imputed['Sulfate']
                df_imputed['Turbidity_Organic'] = df_imputed['Turbidity'] * df_imputed['Organic_carbon']
                df_imputed['Hardness_Chloramines'] = df_imputed['Hardness'] * df_imputed['Chloramines']
                df_imputed['Trihalomethanes_Chloramines'] = df_imputed['Trihalomethanes'] * df_imputed['Chloramines']
                df_imputed['ph_squared'] = df_imputed['ph'] ** 2
                df_imputed['ph_cubed'] = df_imputed['ph'] ** 3
                df_imputed['Sulfate_squared'] = df_imputed['Sulfate'] ** 2
                df_imputed['Hardness_squared'] = df_imputed['Hardness'] ** 2
                df_imputed['Chloramines_squared'] = df_imputed['Chloramines'] ** 2
                df_imputed['Turbidity_squared'] = df_imputed['Turbidity'] ** 2
                df_imputed['Solids_Conductivity_ratio'] = df_imputed['Solids'] / (df_imputed['Conductivity'] + 1)
                df_imputed['Organic_Turbidity_ratio'] = df_imputed['Organic_carbon'] / (df_imputed['Turbidity'] + 0.01)
                df_imputed['Chloramines_Sulfate_ratio'] = df_imputed['Chloramines'] / (df_imputed['Sulfate'] + 1)
                df_imputed['Hardness_ph_ratio'] = df_imputed['Hardness'] / (df_imputed['ph'] + 1)
                df_imputed['Trihalomethanes_Organic_ratio'] = df_imputed['Trihalomethanes'] / (df_imputed['Organic_carbon'] + 1)
                df_imputed['Sulfate_Conductivity_ratio'] = df_imputed['Sulfate'] / (df_imputed['Conductivity'] + 1)
                
                for col in ['Solids', 'Hardness', 'Sulfate', 'Conductivity']:
                    df_imputed[f'{col}_log'] = np.log1p(df_imputed[col])
                
                df_imputed['chemical_sum'] = (df_imputed['Chloramines'] + df_imputed['Sulfate'] + 
                                              df_imputed['Organic_carbon'] + df_imputed['Trihalomethanes'])
                df_imputed['chemical_mean'] = df_imputed['chemical_sum'] / 4
                df_imputed['chemical_std'] = original_features[['Chloramines', 'Sulfate', 'Organic_carbon', 'Trihalomethanes']].std(axis=1)
                df_imputed['chemical_max'] = original_features[['Chloramines', 'Sulfate', 'Organic_carbon', 'Trihalomethanes']].max(axis=1)
                df_imputed['chemical_min'] = original_features[['Chloramines', 'Sulfate', 'Organic_carbon', 'Trihalomethanes']].min(axis=1)
                df_imputed['ph_acidic'] = (df_imputed['ph'] < 6.5).astype(int)
                df_imputed['ph_basic'] = (df_imputed['ph'] > 8.5).astype(int)
                df_imputed['ph_optimal'] = ((df_imputed['ph'] >= 6.5) & (df_imputed['ph'] <= 8.5)).astype(int)
                df_imputed['high_turbidity'] = (df_imputed['Turbidity'] > 5).astype(int)
                df_imputed['high_hardness'] = (df_imputed['Hardness'] > 200).astype(int)
                df_imputed['ph_distance'] = np.abs(df_imputed['ph'] - 7.0)
                
                X = df_imputed.drop('Potability', axis=1)
                y = df_imputed['Potability']
                
                status_text.text("Step 3/7: Selecting best features...")
                progress_bar.progress(35)
                rf_selector = ExtraTreesClassifier(n_estimators=100, random_state=42, n_jobs=-1)
                rf_selector.fit(X, y)
                selector = SelectFromModel(rf_selector, threshold='0.5*mean', prefit=True)
                X_selected = selector.transform(X)
                selected_features = X.columns[selector.get_support()].tolist()
                st.session_state.selected_features = selected_features
                X = pd.DataFrame(X_selected, columns=selected_features)
                
                status_text.text("Step 4/7: Scaling features...")
                progress_bar.progress(45)
                scaler = QuantileTransformer(n_quantiles=1000, output_distribution='normal', random_state=42)
                X_scaled = scaler.fit_transform(X)
                st.session_state.scaler = scaler
                
                status_text.text("Step 5/7: Balancing classes with SMOTEENN...")
                progress_bar.progress(55)
                smote_enn = SMOTEENN(random_state=42)
                X_res, y_res = smote_enn.fit_resample(X_scaled, y)
                
                X_train, X_test, y_train, y_test = train_test_split(
                    X_res, y_res, test_size=0.2, random_state=42, stratify=y_res
                )
                
                status_text.text("Step 6/7: Training models...")
                
                models = {}
                model_scores = {}
                predictions_dict = {}
                
        
                progress_bar.progress(60)
                lgbm = LGBMClassifier(n_estimators=800, learning_rate=0.02, max_depth=8, num_leaves=40,
                                     min_child_samples=15, subsample=0.85, colsample_bytree=0.85,
                                     reg_alpha=0.3, reg_lambda=0.3, random_state=42, verbose=-1, n_jobs=-1)
                lgbm.fit(X_train, y_train)
                models['LightGBM'] = lgbm
                
                progress_bar.progress(70)
                catboost = CatBoostClassifier(iterations=800, learning_rate=0.02, depth=8,
                                             l2_leaf_reg=5, border_count=128, random_seed=42, verbose=False)
                catboost.fit(X_train, y_train)
                models['CatBoost'] = catboost
                
                progress_bar.progress(80)
                et = ExtraTreesClassifier(n_estimators=800, max_depth=15, min_samples_split=4,
                                         min_samples_leaf=2, max_features='sqrt', random_state=42, n_jobs=-1)
                et.fit(X_train, y_train)
                models['Extra Trees'] = et
                
                progress_bar.progress(85)
                nn = MLPClassifier(hidden_layer_sizes=(128, 64, 32), activation='relu', solver='adam',
                                  alpha=0.001, learning_rate='adaptive', max_iter=500, random_state=42)
                nn.fit(X_train, y_train)
                models['Neural Network'] = nn
                
                for name, model in models.items():
                    y_pred_proba = model.predict_proba(X_test)[:, 1]
                    predictions_dict[name] = y_pred_proba
                    acc = accuracy_score(y_test, model.predict(X_test))
                    auc = roc_auc_score(y_test, y_pred_proba)
                    model_scores[name] = {'accuracy': acc, 'auc': auc}
                
                status_text.text("Step 7/7: Creating ensemble...")
                progress_bar.progress(95)
                
                weights_auc = np.array([model_scores[name]['auc'] for name in models.keys()])
                weights_auc = weights_auc / weights_auc.sum()
                
                ensemble_proba = np.average([predictions_dict[name] for name in models.keys()],
                                           axis=0, weights=weights_auc)
                
                best_acc = 0
                best_threshold = 0.5
                for thresh in np.arange(0.4, 0.7, 0.01):
                    pred_temp = (ensemble_proba > thresh).astype(int)
                    acc_temp = accuracy_score(y_test, pred_temp)
                    if acc_temp > best_acc:
                        best_acc = acc_temp
                        best_threshold = thresh
                
                st.session_state.models = models
                st.session_state.best_threshold = best_threshold
                st.session_state.X_test = X_test
                st.session_state.y_test = y_test
                st.session_state.model_scores = model_scores
                st.session_state.trained = True
                
                progress_bar.progress(100)
                status_text.text("‚úÖ Training Complete!")
                
                st.success(f"### üéâ Training Successful!")
                st.balloons()
                
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("Ensemble Accuracy", f"{best_acc:.2%}")
                with col2:
                    st.metric("Features Selected", len(selected_features))
                with col3:
                    st.metric("Optimal Threshold", f"{best_threshold:.3f}")
                
                st.info("Navigate to 'Model Performance' to see detailed metrics!")

elif page == "Predict":
    st.markdown("##  Make Predictions")
    
    if not st.session_state.trained:
        st.warning("‚ö†Ô∏è Please train the models first!")
    else:
        st.markdown("### Enter Water Quality Parameters")
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            ph = st.number_input("pH", min_value=0.0, max_value=14.0, value=7.0, step=0.1)
            hardness = st.number_input("Hardness (mg/L)", min_value=0.0, value=200.0, step=1.0)
            solids = st.number_input("Solids (ppm)", min_value=0.0, value=20000.0, step=100.0)
        
        with col2:
            chloramines = st.number_input("Chloramines (ppm)", min_value=0.0, value=7.0, step=0.1)
            sulfate = st.number_input("Sulfate (mg/L)", min_value=0.0, value=333.0, step=1.0)
            conductivity = st.number_input("Conductivity (ŒºS/cm)", min_value=0.0, value=400.0, step=1.0)
        
        with col3:
            organic_carbon = st.number_input("Organic Carbon (ppm)", min_value=0.0, value=14.0, step=0.1)
            trihalomethanes = st.number_input("Trihalomethanes (Œºg/L)", min_value=0.0, value=66.0, step=0.1)
            turbidity = st.number_input("Turbidity (NTU)", min_value=0.0, value=4.0, step=0.1)
        
        if st.button("üîç Predict Potability", use_container_width=True):
            input_data = pd.DataFrame({
                'ph': [ph], 'Hardness': [hardness], 'Solids': [solids],
                'Chloramines': [chloramines], 'Sulfate': [sulfate],
                'Conductivity': [conductivity], 'Organic_carbon': [organic_carbon],
                'Trihalomethanes': [trihalomethanes], 'Turbidity': [turbidity]
            })
            
            input_data['ph_Hardness'] = input_data['ph'] * input_data['Hardness']
            input_data['ph_Sulfate'] = input_data['ph'] * input_data['Sulfate']
            input_data['Solids_Sulfate'] = input_data['Solids'] * input_data['Sulfate']
            input_data['Solids_Conductivity'] = input_data['Solids'] * input_data['Conductivity']
            input_data['Organic_Chloramines'] = input_data['Organic_carbon'] * input_data['Chloramines']
            input_data['Conductivity_Sulfate'] = input_data['Conductivity'] * input_data['Sulfate']
            input_data['Turbidity_Organic'] = input_data['Turbidity'] * input_data['Organic_carbon']
            input_data['Hardness_Chloramines'] = input_data['Hardness'] * input_data['Chloramines']
            input_data['Trihalomethanes_Chloramines'] = input_data['Trihalomethanes'] * input_data['Chloramines']
            input_data['ph_squared'] = input_data['ph'] ** 2
            input_data['ph_cubed'] = input_data['ph'] ** 3
            input_data['Sulfate_squared'] = input_data['Sulfate'] ** 2
            input_data['Hardness_squared'] = input_data['Hardness'] ** 2
            input_data['Chloramines_squared'] = input_data['Chloramines'] ** 2
            input_data['Turbidity_squared'] = input_data['Turbidity'] ** 2
            input_data['Solids_Conductivity_ratio'] = input_data['Solids'] / (input_data['Conductivity'] + 1)
            input_data['Organic_Turbidity_ratio'] = input_data['Organic_carbon'] / (input_data['Turbidity'] + 0.01)
            input_data['Chloramines_Sulfate_ratio'] = input_data['Chloramines'] / (input_data['Sulfate'] + 1)
            input_data['Hardness_ph_ratio'] = input_data['Hardness'] / (input_data['ph'] + 1)
            input_data['Trihalomethanes_Organic_ratio'] = input_data['Trihalomethanes'] / (input_data['Organic_carbon'] + 1)
            input_data['Sulfate_Conductivity_ratio'] = input_data['Sulfate'] / (input_data['Conductivity'] + 1)
            
            for col in ['Solids', 'Hardness', 'Sulfate', 'Conductivity']:
                input_data[f'{col}_log'] = np.log1p(input_data[col])
            
            input_data['chemical_sum'] = (input_data['Chloramines'] + input_data['Sulfate'] + 
                                         input_data['Organic_carbon'] + input_data['Trihalomethanes'])
            input_data['chemical_mean'] = input_data['chemical_sum'] / 4
            input_data['chemical_std'] = input_data[['Chloramines', 'Sulfate', 'Organic_carbon', 'Trihalomethanes']].std(axis=1)
            input_data['chemical_max'] = input_data[['Chloramines', 'Sulfate', 'Organic_carbon', 'Trihalomethanes']].max(axis=1)
            input_data['chemical_min'] = input_data[['Chloramines', 'Sulfate', 'Organic_carbon', 'Trihalomethanes']].min(axis=1)
            input_data['ph_acidic'] = (input_data['ph'] < 6.5).astype(int)
            input_data['ph_basic'] = (input_data['ph'] > 8.5).astype(int)
            input_data['ph_optimal'] = ((input_data['ph'] >= 6.5) & (input_data['ph'] <= 8.5)).astype(int)
            input_data['high_turbidity'] = (input_data['Turbidity'] > 5).astype(int)
            input_data['high_hardness'] = (input_data['Hardness'] > 200).astype(int)
            input_data['ph_distance'] = np.abs(input_data['ph'] - 7.0)
            
            input_data = input_data[st.session_state.selected_features]
            
            input_scaled = st.session_state.scaler.transform(input_data)
            
            predictions = {}
            for name, model in st.session_state.models.items():
                pred_proba = model.predict_proba(input_scaled)[0, 1]
                predictions[name] = pred_proba
            
            model_scores = st.session_state.model_scores
            weights = np.array([model_scores[name]['auc'] for name in st.session_state.models.keys()])
            weights = weights / weights.sum()
            
            ensemble_proba = np.average(list(predictions.values()), weights=weights)
            ensemble_pred = 1 if ensemble_proba > st.session_state.best_threshold else 0
            
            st.markdown("---")
            st.markdown("###  Prediction Results")
            
            col1, col2 = st.columns(2)
            
            with col1:
                if ensemble_pred == 1:
                    st.success("### ‚úÖ POTABLE")
                    st.markdown("<p style='color: #1f2937; font-weight: bold;'>The water is safe for consumption!</p>", unsafe_allow_html=True)
                    st.markdown(f"<p style='color: #1f2937; font-weight: bold;'>Confidence: {ensemble_proba*100:.2f}%</p>", unsafe_allow_html=True)
                else:
                    st.error("### ‚ùå NOT POTABLE")
                    st.markdown("<p style='color: #1f2937; font-weight: bold;'>The water is NOT safe for consumption!</p>", unsafe_allow_html=True)
                    st.markdown(f"<p style='color: #1f2937; font-weight: bold;'>Confidence: {(1-ensemble_proba)*100:.2f}%</p>", unsafe_allow_html=True)
            
            with col2:
                st.markdown("<h4 style='color: #1f2937;'>Model Predictions:</h4>", unsafe_allow_html=True)
                for name, prob in predictions.items():
                    st.progress(prob, text=f"{name}: {prob*100:.2f}%")
            
            st.markdown("---")
            st.markdown("<h3 style='color: #1f2937;'> Parameter Analysis</h3>", unsafe_allow_html=True)
            
            

elif page == "Model Performance":
    st.markdown("##  Model Performance Metrics")
    
    if not st.session_state.trained:
        st.warning("‚ö†Ô∏è Please train the models first!")
    else:
        model_scores = st.session_state.model_scores
        models = st.session_state.models
        X_test = st.session_state.X_test
        y_test = st.session_state.y_test
        st.session_state.trained = True

        
        predictions_dict = {}
        for name, model in models.items():
            predictions_dict[name] = model.predict_proba(X_test)[:, 1]
        
        weights = np.array([model_scores[name]['auc'] for name in models.keys()])
        weights = weights / weights.sum()
        ensemble_proba = np.average(list(predictions_dict.values()), axis=0, weights=weights)
        ensemble_pred = (ensemble_proba > st.session_state.best_threshold).astype(int)
        
        ensemble_acc = accuracy_score(y_test, ensemble_pred)
        ensemble_auc = roc_auc_score(y_test, ensemble_proba)
        ensemble_f1 = f1_score(y_test, ensemble_pred)
        
        st.markdown("###  Overall Performance")
        
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("Ensemble Accuracy", f"{ensemble_acc:.2%}", delta=f"+{(ensemble_acc-0.69)*100:.1f}%")
        with col2:
            st.metric("ROC-AUC Score", f"{ensemble_auc:.4f}")
        with col3:
            st.metric("F1-Score", f"{ensemble_f1:.4f}")
        with col4:
            st.metric("Optimal Threshold", f"{st.session_state.best_threshold:.3f}")
        
        st.markdown("---")
        
        st.markdown("### üìä Individual Model Performance")
        
        perf_data = []
        for name in models.keys():
            y_pred = models[name].predict(X_test)
            acc = accuracy_score(y_test, y_pred)
            auc = model_scores[name]['auc']
            f1 = f1_score(y_test, y_pred)
            perf_data.append({'Model': name, 'Accuracy': f"{acc:.4f}", 
                            'ROC-AUC': f"{auc:.4f}", 'F1-Score': f"{f1:.4f}"})
        
        perf_data.append({'Model': 'Weighted Ensemble', 'Accuracy': f"{ensemble_acc:.4f}",
                         'ROC-AUC': f"{ensemble_auc:.4f}", 'F1-Score': f"{ensemble_f1:.4f}"})
        
        perf_df = pd.DataFrame(perf_data)
        st.dataframe(perf_df, use_container_width=True, hide_index=True)
        
        st.markdown("---")
        
        tab1, tab2, tab3 = st.tabs(["Confusion Matrix", "Model Comparison", "Feature Importance"])
        
        with tab1:
            st.markdown("#### Confusion Matrix - Ensemble Model")
            
            cm = confusion_matrix(y_test, ensemble_pred)
            
            fig, ax = plt.subplots(figsize=(8, 6))
            sns.heatmap(cm, annot=True, fmt='d', cmap='RdYlGn', 
                       xticklabels=['Not Potable', 'Potable'], 
                       yticklabels=['Not Potable', 'Potable'], 
                       cbar_kws={'label': 'Count'}, annot_kws={'size': 14, 'weight': 'bold'}, ax=ax)
            ax.set_title(f'Confusion Matrix - Weighted Ensemble\nAccuracy: {ensemble_acc:.4f}', 
                        fontsize=14, fontweight='bold', pad=15)
            ax.set_xlabel('Predicted Label', fontsize=12, fontweight='bold')
            ax.set_ylabel('True Label', fontsize=12, fontweight='bold')
            
            st.pyplot(fig)
            
            st.markdown("#### Classification Report")
            report = classification_report(y_test, ensemble_pred, target_names=['Not Potable', 'Potable'], output_dict=True)
            report_df = pd.DataFrame(report).transpose()
            st.dataframe(report_df, use_container_width=True)
        
        with tab2:
            st.markdown("#### Model Performance Comparison")
            
            model_names = list(model_scores.keys()) + ['Ensemble']
            accuracies = [accuracy_score(y_test, models[m].predict(X_test)) for m in model_scores.keys()] + [ensemble_acc]
            aucs = [model_scores[m]['auc'] for m in model_scores.keys()] + [ensemble_auc]
            f1s = [f1_score(y_test, models[m].predict(X_test)) for m in model_scores.keys()] + [ensemble_f1]
            
            fig, axes = plt.subplots(1, 3, figsize=(16, 5))
            
            colors = ['#95E1D3'] * len(model_scores) + ['#F38181']
            
            axes[0].barh(model_names, accuracies, color=colors, edgecolor='black', linewidth=1.5)
            axes[0].set_xlabel('Accuracy', fontweight='bold', fontsize=11)
            axes[0].set_title('Accuracy Comparison', fontweight='bold', fontsize=13)
            axes[0].set_xlim(0.80, 0.92)
            for i, v in enumerate(accuracies):
                axes[0].text(v + 0.002, i, f'{v:.4f}', va='center', fontweight='bold')
            
            axes[1].barh(model_names, aucs, color=colors, edgecolor='black', linewidth=1.5)
            axes[1].set_xlabel('ROC-AUC', fontweight='bold', fontsize=11)
            axes[1].set_title('ROC-AUC Comparison', fontweight='bold', fontsize=13)
            axes[1].set_xlim(0.90, 0.96)
            for i, v in enumerate(aucs):
                axes[1].text(v + 0.002, i, f'{v:.4f}', va='center', fontweight='bold')
            
            axes[2].barh(model_names, f1s, color=colors, edgecolor='black', linewidth=1.5)
            axes[2].set_xlabel('F1-Score', fontweight='bold', fontsize=11)
            axes[2].set_title('F1-Score Comparison', fontweight='bold', fontsize=13)
            axes[2].set_xlim(0.85, 0.93)
            for i, v in enumerate(f1s):
                axes[2].text(v + 0.002, i, f'{v:.4f}', va='center', fontweight='bold')
            
            plt.tight_layout()
            st.pyplot(fig)
        
        with tab3:
            st.markdown("#### Top 15 Feature Importance - CatBoost Model")
            
            selected_features = st.session_state.selected_features
            importance = pd.Series(models['CatBoost'].feature_importances_, 
                                 index=selected_features).sort_values(ascending=True)
            
            fig, ax = plt.subplots(figsize=(10, 8))
            colors_imp = plt.cm.viridis(np.linspace(0.3, 0.9, len(importance.tail(15))))
            importance.tail(15).plot(kind='barh', color=colors_imp, edgecolor='black', linewidth=1.5, ax=ax)
            ax.set_xlabel('Feature Importance', fontsize=12, fontweight='bold')
            ax.set_title('Top 15 Most Important Features', fontsize=14, fontweight='bold', pad=15)
            
            st.pyplot(fig)
        
        st.markdown("---")
        st.markdown("---")

# Success message box (custom HTML)
        st.markdown("""
             <div style='background-color:#D1FAE5; padding:15px; border-radius:10px;'>
             <h3 style='color:#065F46;'>üéâ Model Training Complete!</h3>
             </div>""",unsafe_allow_html=True)

# Info box for metrics
        st.markdown(f"""
             <div style='background-color:#DBEAFE; padding:15px; border-radius:10px; color:#1f2937;'>
             <strong>Key Achievements:</strong><br>
             ‚úÖ Accuracy: {ensemble_acc:.2%}<br>
             ‚úÖ Improvement: +{((ensemble_acc - 0.69) / 0.69 * 100):.1f}% from baseline<br>
             ‚úÖ ROC-AUC: {ensemble_auc:.4f}<br>
             ‚úÖ Well-balanced predictions across both classes
             </div>""",unsafe_allow_html=True)


st.markdown("---")
st.markdown("""
<div style='text-align: center; color: #1f2937; padding: 20px;'>
    <p><strong>üíß Water Potability Prediction System | Built with Streamlit & Machine Learning</strong></p>
    <p>Powered by LightGBM, CatBoost, Extra Trees & Neural Networks</p>
</div>
""", unsafe_allow_html=True)